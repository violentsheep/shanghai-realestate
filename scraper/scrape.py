#!/usr/bin/env python3
"""
ä¸Šæµ·æˆ¿åœ°äº§æ•°æ®é‡‡é›†è„šæœ¬
ç­–ç•¥ï¼šPlaywright æ— å¤´æµè§ˆå™¨æ¸²æŸ“é¡µé¢ â†’ æå–é¡µé¢æ–‡æœ¬ â†’ MiniMax æ–‡æœ¬æ¨¡å‹ + æ­£åˆ™åŒé‡è§£æ
æ•°æ®æºï¼šç½‘ä¸Šæˆ¿åœ°äº§ fangdi.com.cnï¼ˆä¸Šæµ·å¸‚æˆ¿åœ°äº§äº¤æ˜“ä¸­å¿ƒï¼Œæ”¿åºœæœºæ„ï¼‰
åˆè§„è¯´æ˜ï¼š
  - åªè®¿é—®å…¬å¼€é¡µé¢ï¼Œæ— éœ€ç™»å½•
  - robots.txt ä¸å­˜åœ¨ï¼ˆ404ï¼‰ï¼Œæ— é™åˆ¶è§„åˆ™
  - æ¸²æŸ“åæå–æ–‡æœ¬ï¼Œä¸ç»•è¿‡ä»»ä½•åçˆ¬æœºåˆ¶
  - æ¯æ¬¡è¯·æ±‚é—´éš” â‰¥6 ç§’ï¼Œåªé‡‡é›†å¿…è¦å­—æ®µ
"""

import asyncio
import json
import os
import re
import sys
import urllib.request
from datetime import date, datetime
from pathlib import Path

from playwright.async_api import async_playwright

# â”€â”€â”€ é…ç½® â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DATA_DIR = Path(__file__).parent.parent / "data" / "history"
DATA_DIR.mkdir(parents=True, exist_ok=True)
HISTORY_FILE = DATA_DIR / "data.json"

MINIMAX_API_KEY = os.environ.get("MINIMAX_API_KEY", "")
MINIMAX_API_URL = "https://api.minimaxi.com/anthropic/v1/messages"

BROWSER_HEADERS = {
    "User-Agent": (
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) "
        "Chrome/122.0.0.0 Safari/537.36"
    ),
    "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
}

URLS = {
    "second_hand": "https://www.fangdi.com.cn/old_house/old_house.html",
    "trade":       "https://www.fangdi.com.cn/trade/trade.html",
}


# â”€â”€â”€ Playwright æå–é¡µé¢æ–‡æœ¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def get_page_text(url: str) -> str:
    """Playwright å®Œæ•´æ¸²æŸ“é¡µé¢ï¼Œç­‰å¾…çœŸå®å†…å®¹åŠ è½½åè¿”å›å¯è§æ–‡æœ¬"""
    async with async_playwright() as p:
        browser = await p.chromium.launch(
            headless=True,
            args=["--no-sandbox", "--disable-dev-shm-usage", "--disable-gpu",
                  "--disable-blink-features=AutomationControlled"],
        )
        ctx = await browser.new_context(
            extra_http_headers=BROWSER_HEADERS,
            viewport={"width": 1280, "height": 900},
            locale="zh-CN",
            user_agent=BROWSER_HEADERS["User-Agent"],
        )
        # éšè— webdriver ç‰¹å¾
        await ctx.add_init_script("""
            Object.defineProperty(navigator, 'webdriver', {get: () => undefined});
        """)
        page = await ctx.new_page()

        print(f"    â†’ è®¿é—® {url}")
        await page.goto(url, wait_until="domcontentloaded", timeout=45000)

        # ç­‰å¾…é¡µé¢çœŸå®å†…å®¹ï¼šæœ€é•¿ç­‰ 15 ç§’ï¼Œæ¯ç§’æ£€æŸ¥ä¸€æ¬¡
        real_content = False
        for i in range(15):
            await page.wait_for_timeout(1000)
            text = await page.inner_text("body")
            # çœŸå®é¡µé¢åŒ…å«"å¥—æ•°"æˆ–"æˆäº¤"æˆ–"æŒ‚ç‰Œ"
            if any(kw in text for kw in ["å¥—æ•°", "æˆäº¤", "æŒ‚ç‰Œ", "å¹³æ–¹ç±³", "ã¡"]):
                real_content = True
                print(f"    â†’ ç¬¬ {i+1}s æ£€æµ‹åˆ°çœŸå®å†…å®¹ï¼ˆ{len(text)} å­—ç¬¦ï¼‰")
                break
            print(f"    â†’ ç¬¬ {i+1}s ç­‰å¾…å†…å®¹åŠ è½½... ({len(text)} å­—)")

        if not real_content:
            print("    âš ï¸  15ç§’å†…æœªæ£€æµ‹åˆ°çœŸå®å†…å®¹ï¼Œå°è¯•ç»§ç»­è§£æ")

        text = await page.inner_text("body")
        await browser.close()

    return text


# â”€â”€â”€ æ­£åˆ™å…œåº•è§£æ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def regex_parse_second_hand(text: str) -> dict:
    """æ­£åˆ™ç›´æ¥ä»æ–‡æœ¬æå–äºŒæ‰‹æˆ¿æ•°æ®"""
    units, area = None, None
    m = re.search(r'æ˜¨æ—¥äºŒæ‰‹æˆ¿æˆäº¤å¥—æ•°[ï¼š:\s]*(\d[\d,]*)\s*å¥—?', text)
    if m:
        units = int(m.group(1).replace(",", ""))
    m = re.search(r'æ˜¨æ—¥äºŒæ‰‹æˆ¿æˆäº¤é¢ç§¯[ï¼š:\s]*([\d,]+\.?\d*)', text)
    if m:
        area = float(m.group(1).replace(",", ""))
    return {"units": units, "area": area}


def regex_parse_listing(text: str) -> int | None:
    """ä»æ–‡æœ¬ä¸­æå–æŒ‚ç‰Œæ€»å¥—æ•°"""
    # æ‰¾æ‰€æœ‰ 5-6 ä½æ•°å­—åé¢è·Ÿ"å¥—"çš„
    nums = re.findall(r'(\d{4,6})\s*å¥—', text)
    if nums:
        return max(int(n) for n in nums)
    return None


def regex_parse_new_house(text: str) -> dict:
    """ä»æ–‡æœ¬ä¸­æå–ä¸€æ‰‹æˆ¿ä»Šæ—¥æˆäº¤"""
    units, area = None, None
    m = re.search(r'ä»Šæ—¥[å…±]?[é¢„å‡ºå”®å„ç±»å•†å“æˆ¿]*\s*(\d[\d,]*)\s*å¥—', text)
    if m:
        units = int(m.group(1).replace(",", ""))
    m = re.search(r'é¢ç§¯\s*([\d,]+\.?\d*)\s*å¹³æ–¹ç±³', text)
    if not m:
        m = re.search(r'ä»Šæ—¥.*?([\d,]+\.?\d{2})\s*ä¸‡?[ã¡å¹³]', text)
    if m:
        val = float(m.group(1).replace(",", ""))
        area = val * 10000 if val < 10000 else val
    return {"units": units, "area": area}


# â”€â”€â”€ MiniMax è§£æï¼ˆæœ‰çœŸå®æ–‡æœ¬æ—¶å¢å¼ºç”¨ï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def ask_minimax(prompt: str) -> str:
    payload = json.dumps({
        "model": "claude-3-5-sonnet-20241022",
        "max_tokens": 300,
        "messages": [{"role": "user", "content": prompt}]
    }).encode("utf-8")

    req = urllib.request.Request(
        MINIMAX_API_URL,
        data=payload,
        headers={
            "x-api-key": MINIMAX_API_KEY,
            "anthropic-version": "2023-06-01",
            "Content-Type": "application/json",
        },
    )
    with urllib.request.urlopen(req, timeout=30) as resp:
        d = json.loads(resp.read())
    for c in d.get("content", []):
        if c.get("type") == "text":
            return c["text"].strip()
    raise RuntimeError(f"æ— æ–‡æœ¬å›å¤: {d}")


def parse_with_minimax(text: str, page_type: str) -> dict:
    """ç”¨ MiniMax ä»æ–‡æœ¬ä¸­æå–ç»“æ„åŒ–æ•°æ®"""
    if page_type == "second_hand":
        prompt = f"""ä»ä¸‹é¢çš„ç½‘é¡µæ–‡æœ¬ä¸­æå–æ•°æ®ï¼Œåªè¿”å›JSONï¼Œä¸è¦ä»»ä½•è§£é‡Šï¼š
{{"units": <æ˜¨æ—¥äºŒæ‰‹æˆ¿æˆäº¤å¥—æ•°ï¼Œæ•´æ•°ï¼Œå¦‚527>, "area": <æ˜¨æ—¥äºŒæ‰‹æˆ¿æˆäº¤é¢ç§¯ï¼Œæµ®ç‚¹æ•°ã¡ï¼Œå¦‚42244.63>}}
æ‰¾ä¸åˆ°çš„å­—æ®µå¡«nullã€‚

æ–‡æœ¬ï¼š
{text[:2000]}"""
    else:
        prompt = f"""ä»ä¸‹é¢çš„ç½‘é¡µæ–‡æœ¬ä¸­æå–æ•°æ®ï¼Œåªè¿”å›JSONï¼Œä¸è¦ä»»ä½•è§£é‡Šï¼š
{{"new_house_units": <ä»Šæ—¥ä¸€æ‰‹æˆ¿æˆäº¤å¥—æ•°ï¼Œæ•´æ•°>, "new_house_area": <ä»Šæ—¥ä¸€æ‰‹æˆ¿æˆäº¤é¢ç§¯ã¡ï¼Œæµ®ç‚¹æ•°ï¼Œè‹¥æ˜¾ç¤ºä¸‡ã¡è¯·Ã—10000>, "listing_total": <äºŒæ‰‹æˆ¿å‡ºå”®æŒ‚ç‰Œå¥—æ•°åˆè®¡ï¼Œæ•´æ•°>}}
æ‰¾ä¸åˆ°çš„å­—æ®µå¡«nullã€‚

æ–‡æœ¬ï¼š
{text[:3000]}"""

    raw = ask_minimax(prompt)
    # æ¸…ç† markdown
    raw = re.sub(r"```json\s*|\s*```", "", raw).strip()
    m = re.search(r"\{.*\}", raw, re.DOTALL)
    if m:
        return json.loads(m.group())
    return json.loads(raw)


# â”€â”€â”€ é‡‡é›†ä»»åŠ¡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def fetch_second_hand(debug_dir: Path) -> dict:
    print("\n  ğŸ“„ é‡‡é›†äºŒæ‰‹æˆ¿æ•°æ®...")
    text = await get_page_text(URLS["second_hand"])
    (debug_dir / f"second_hand_{date.today()}.txt").write_text(text, encoding="utf-8")

    has_real = any(kw in text for kw in ["å¥—æ•°", "æˆäº¤", "æ˜¨æ—¥"])

    if has_real and MINIMAX_API_KEY:
        try:
            result = parse_with_minimax(text, "second_hand")
            if result.get("units") or result.get("area"):
                print(f"  âœ… MiniMaxè§£æ: {result}")
                return result
        except Exception as e:
            print(f"  âš ï¸  MiniMaxè§£æå¤±è´¥({e})ï¼Œé™çº§ç”¨æ­£åˆ™")

    result = regex_parse_second_hand(text)
    print(f"  âœ… æ­£åˆ™è§£æ: {result}")
    return result


async def fetch_trade(debug_dir: Path) -> dict:
    print("\n  ğŸ“„ é‡‡é›†äº¤æ˜“ç»Ÿè®¡æ•°æ®...")
    text = await get_page_text(URLS["trade"])
    (debug_dir / f"trade_{date.today()}.txt").write_text(text, encoding="utf-8")

    has_real = any(kw in text for kw in ["å¥—æ•°", "æˆäº¤", "æŒ‚ç‰Œ"])

    if has_real and MINIMAX_API_KEY:
        try:
            result = parse_with_minimax(text, "trade")
            if any(result.get(k) for k in ["new_house_units", "listing_total"]):
                print(f"  âœ… MiniMaxè§£æ: {result}")
                return result
        except Exception as e:
            print(f"  âš ï¸  MiniMaxè§£æå¤±è´¥({e})ï¼Œé™çº§ç”¨æ­£åˆ™")

    nh = regex_parse_new_house(text)
    listing = regex_parse_listing(text)
    result = {
        "new_house_units": nh.get("units"),
        "new_house_area": nh.get("area"),
        "listing_total": listing,
    }
    print(f"  âœ… æ­£åˆ™è§£æ: {result}")
    return result


# â”€â”€â”€ æ•°æ®å­˜å‚¨ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def load_history() -> list:
    if HISTORY_FILE.exists():
        return json.loads(HISTORY_FILE.read_text(encoding="utf-8"))
    return []


def save_history(records: list):
    HISTORY_FILE.write_text(
        json.dumps(records, ensure_ascii=False, indent=2),
        encoding="utf-8",
    )


def avg_area(units, area):
    try:
        if units and area and float(units) > 0:
            return round(float(area) / float(units), 2)
    except Exception:
        pass
    return None


# â”€â”€â”€ ä¸»æµç¨‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def main():
    today = date.today().isoformat()
    print(f"\nğŸ  ä¸Šæµ·æˆ¿åœ°äº§æ•°æ®é‡‡é›† [{today}]")
    print("â”€" * 45)

    history = load_history()
    if any(r["date"] == today for r in history) and "--force" not in sys.argv:
        print("âš ï¸  ä»Šæ—¥æ•°æ®å·²å­˜åœ¨ï¼Œè·³è¿‡ï¼ˆåŠ  --force å¼ºåˆ¶é‡é‡‡ï¼‰")
        return

    debug_dir = DATA_DIR / "debug"
    debug_dir.mkdir(exist_ok=True)

    sh, trade = {}, {}

    try:
        sh = await fetch_second_hand(debug_dir)
    except Exception as e:
        print(f"  âŒ äºŒæ‰‹æˆ¿é‡‡é›†å¼‚å¸¸: {e}")

    print("\n  â³ ç­‰å¾… 6 ç§’ï¼ˆåˆè§„é—´éš”ï¼‰...")
    await asyncio.sleep(6)

    try:
        trade = await fetch_trade(debug_dir)
    except Exception as e:
        print(f"  âŒ äº¤æ˜“ç»Ÿè®¡é‡‡é›†å¼‚å¸¸: {e}")

    sh_u = sh.get("units")
    sh_a = sh.get("area")
    nh_u = trade.get("new_house_units")
    nh_a = trade.get("new_house_area")
    li_t = trade.get("listing_total")

    record = {
        "date": today,
        "scraped_at": datetime.now().isoformat(timespec="seconds"),
        "second_hand": {
            "units":    sh_u,
            "area":     sh_a,
            "avg_area": avg_area(sh_u, sh_a),
            "note":     "æ˜¨æ—¥ç½‘ç­¾æˆäº¤ï¼ˆT+1ï¼‰",
        },
        "new_house": {
            "units":    nh_u,
            "area":     nh_a,
            "avg_area": avg_area(nh_u, nh_a),
            "note":     "ä»Šæ—¥æˆäº¤ï¼ˆå½“æ—¥ç´¯è®¡ï¼‰",
        },
        "listing": {
            "total": li_t,
            "note":  "äºŒæ‰‹æˆ¿å‡ºå”®æŒ‚ç‰Œå¥—æ•°",
        },
    }

    history = [r for r in history if r["date"] != today]
    history.append(record)
    history.sort(key=lambda x: x["date"])
    save_history(history)

    print(f"\nâœ… å·²ä¿å­˜ â†’ {HISTORY_FILE}")
    print(json.dumps(record, ensure_ascii=False, indent=2))


if __name__ == "__main__":
    asyncio.run(main())
